{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-04T09:47:04.522446Z","iopub.execute_input":"2024-03-04T09:47:04.522836Z","iopub.status.idle":"2024-03-04T09:47:04.530595Z","shell.execute_reply.started":"2024-03-04T09:47:04.522804Z","shell.execute_reply":"2024-03-04T09:47:04.529642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **1_Загрузка_данных**","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ndf.head(4)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T09:47:06.955481Z","iopub.execute_input":"2024-03-04T09:47:06.955884Z","iopub.status.idle":"2024-03-04T09:47:09.465375Z","shell.execute_reply.started":"2024-03-04T09:47:06.955853Z","shell.execute_reply":"2024-03-04T09:47:09.464424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"execution":{"iopub.status.busy":"2024-03-04T06:55:12.049869Z","iopub.execute_input":"2024-03-04T06:55:12.050597Z","iopub.status.idle":"2024-03-04T06:55:12.058177Z","shell.execute_reply.started":"2024-03-04T06:55:12.050561Z","shell.execute_reply":"2024-03-04T06:55:12.057308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport cv2\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nfrom torchvision import transforms, models, datasets\nimport torch.nn as nn\nimport torch.optim as optim\n\nimport os\nimport time\nimport glob\nfrom tqdm import tqdm\nfrom collections import defaultdict\nfrom IPython.display import clear_output\n%matplotlib inline\nimport torch.nn.functional as F\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-03-04T09:47:57.454925Z","iopub.execute_input":"2024-03-04T09:47:57.455342Z","iopub.status.idle":"2024-03-04T09:47:57.465120Z","shell.execute_reply.started":"2024-03-04T09:47:57.455309Z","shell.execute_reply":"2024-03-04T09:47:57.464119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **2_Разбивка_данных_train/val**","metadata":{}},{"cell_type":"code","source":"# Разбивка данных на основе индекса\nfrom sklearn.model_selection import train_test_split\ntrn_ids, val_ids = train_test_split(df.index, test_size=0.3, random_state=99)\n# типа разбивка df на train_df и val_df на основе разбивки train_test_split\ntrn_df, val_df = df[df.index.isin(trn_ids)], df[df.index.isin(val_ids)]\n#print(trn_df, val_df)\nlen(trn_df), len(val_df)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T09:47:14.188667Z","iopub.execute_input":"2024-03-04T09:47:14.189348Z","iopub.status.idle":"2024-03-04T09:47:14.314141Z","shell.execute_reply.started":"2024-03-04T09:47:14.189319Z","shell.execute_reply":"2024-03-04T09:47:14.313227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trn_ids, val_ids = train_test_split(trn_df.index, test_size=0.3, random_state=99)\n# trn_df, val_df = df[df.index.isin(trn_ids)], df[df.index.isin(val_ids)]\n# len(trn_df), len(val_df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# сбрасываем индексы\ntrn_df.reset_index(drop=True, inplace=True)\nval_df.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T09:47:24.956574Z","iopub.execute_input":"2024-03-04T09:47:24.956921Z","iopub.status.idle":"2024-03-04T09:47:24.962118Z","shell.execute_reply.started":"2024-03-04T09:47:24.956895Z","shell.execute_reply":"2024-03-04T09:47:24.961160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn_df.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-03-04T09:47:27.314513Z","iopub.execute_input":"2024-03-04T09:47:27.315172Z","iopub.status.idle":"2024-03-04T09:47:27.323324Z","shell.execute_reply.started":"2024-03-04T09:47:27.315142Z","shell.execute_reply":"2024-03-04T09:47:27.322302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-03-04T09:47:28.922279Z","iopub.execute_input":"2024-03-04T09:47:28.922642Z","iopub.status.idle":"2024-03-04T09:47:28.930939Z","shell.execute_reply.started":"2024-03-04T09:47:28.922611Z","shell.execute_reply":"2024-03-04T09:47:28.929740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**определили trn_df, val_df**","metadata":{}},{"cell_type":"markdown","source":"# **3_Компановка_даннх**","metadata":{}},{"cell_type":"code","source":"t = np.array(df.iloc[np.random.randint(300),1:]).reshape(28,-1)\npic=[]\nfor i in np.arange(3):\n    pic.append(t)\narrImg = np.array(pic).transpose(1, 2, 0)\nprint(arrImg.shape)\n\n# должен быть массив array, форма (28, 28, 3)\nplt.imshow(arrImg)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T09:47:31.961132Z","iopub.execute_input":"2024-03-04T09:47:31.961824Z","iopub.status.idle":"2024-03-04T09:47:32.224858Z","shell.execute_reply.started":"2024-03-04T09:47:31.961791Z","shell.execute_reply":"2024-03-04T09:47:32.223999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class Asbooka(Dataset):\n#     def __init__(self, df):\n#         self.df = df\n#         self.pics = np.array(df.iloc[:,1:])\n#         self.targets = np.array(df.iloc[:,0])\n#         self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n#     def __len__(self): return len(self.targets)\n#     def __getitem__(self, ix):\n        \n#         f = self.pics[ix].reshape(28,-1)\n#         pic=[]\n#         for i in np.arange(3):\n#             pic.append(f)\n#         im = np.array(torch.tensor(pic).permute(1,2,0))\n#         im = cv2.resize(im.astype('float32'), (224,224))\n#         im = torch.tensor(im/255)\n#         im = im.permute(2,0,1)\n#         im = self.normalize(im) \n#         target = self.targets[ix]\n#         return im.float(), torch.tensor(target)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def get_data():\n#     train = Asbooka(trn_df)\n#     trn_dl = DataLoader(train, batch_size=64, shuffle=True, drop_last = True)\n#     val = Asbooka(val_df)\n#     val_dl = DataLoader(val, batch_size=32, shuffle=True, drop_last = True)\n#     return train, trn_dl, val_dl\n# train, trn_dl, val_dl = get_data()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # train = Asbooka(val_dl)\n# for i in train:\n#     print(i)\n#     break","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **4_Вытаскиваем_модель,_меняем_слои**","metadata":{}},{"cell_type":"code","source":"from torch.optim import SGD, Adam\nimport torch.nn as nn\ndef get_model():\n    class neuralnet(nn.Module):\n        def __init__(self):\n            super().__init__()\n            model = models.resnet18()\n            #------------------------------\n            # меняем выходной слой\n            model.fc = nn.Linear(in_features=512, out_features=10)\n#             model.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n#             model.fc = nn.Sequential(\n#               nn.Flatten(),\n#               nn.Linear(512, 128), # 512 for resnet18 or 2048 for resnet 50\n#               nn.ReLU(inplace=True),\n#               nn.Dropout(.2),\n#               nn.Linear(128, 1),\n#               nn.Sigmoid()\n#             )\n            #------------------------------\n            # замораживаем слои\n            freeze_layers = [model.layer1, model.layer2, model.conv1, model.bn1]#, model.layer3]\n            for layer in freeze_layers:\n               for param in layer.parameters():\n                 param.requires_grad = False\n            #------------------------------\n            self.model = model\n        def forward(self, x):\n            x = self.model(x)\n            return x\n    model = neuralnet().model\n\n    loss_fn = nn.CrossEntropyLoss()\n    optimizer = Adam(model.parameters(), lr=0.01)\n    return model.to(device), loss_fn, optimizer\nmodel, loss_fn, optimizer = get_model()","metadata":{"execution":{"iopub.status.busy":"2024-03-04T09:52:35.956323Z","iopub.execute_input":"2024-03-04T09:52:35.957175Z","iopub.status.idle":"2024-03-04T09:52:36.172479Z","shell.execute_reply.started":"2024-03-04T09:52:35.957143Z","shell.execute_reply":"2024-03-04T09:52:36.171633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T10:17:17.475835Z","iopub.execute_input":"2024-03-04T10:17:17.476209Z","iopub.status.idle":"2024-03-04T10:17:17.482253Z","shell.execute_reply.started":"2024-03-04T10:17:17.476180Z","shell.execute_reply":"2024-03-04T10:17:17.481341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# здесь разбиваются скорости корректировок для весов и смещений\n# optm = torch.optim.SGD ([\n#     {'params': model.weight, 'weight_decay': 0.5},\n#     {'params': model.bias, 'weight_decay': 0.0}\n# ],lr=1e-3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# глядим замороженные/размороженные слои\nfor name, param in model.named_parameters():\n    print(name,param.requires_grad)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fc","metadata":{"execution":{"iopub.status.busy":"2024-03-04T09:48:15.195036Z","iopub.execute_input":"2024-03-04T09:48:15.195405Z","iopub.status.idle":"2024-03-04T09:48:15.201596Z","shell.execute_reply.started":"2024-03-04T09:48:15.195376Z","shell.execute_reply":"2024-03-04T09:48:15.200732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Пример вставкт L1 и L2 регуляризации**","metadata":{}},{"cell_type":"code","source":"#     outputs=model(inputs)\n#     loss=loss_fn(outputs,labels)\n    \n#     #Replaces pow(2.0) with abs() for L1 regularization\n     \n#     l2_lambda = 0.001\n#     l2_norm = sum(p.pow(2.0).sum()\n#                   for p in model.parameters())\n \n#     loss = loss + l2_lambda * l2_norm","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Оптимизатор SGD в PyTorch уже имеет параметр weight_decay, который соответствует L2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# здесь разбиваются скорости корректировок для весов и смещений\n# optm = torch.optim.SGD ([\n#     {'params': model.weight, 'weight_decay': 0.5},\n#     {'params': model.bias, 'weight_decay': 0.0}\n# ],lr=1e-3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **5_Аугментация**","metadata":{}},{"cell_type":"code","source":"IMG_SIZE = 28\n# Transformations for the train\ntrain_trans = transforms.Compose(([\n    transforms.ToPILImage(),\n    transforms.Resize((224,224)),\n#     transforms.RandomVerticalFlip(0.4), \n#     transforms.RandomHorizontalFlip(0.4),  \n#     transforms.RandomRotation(50,expand=True),\n#     transforms.RandomCrop(IMG_SIZE), \n    transforms.ToTensor(), # делится на 255\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n#     transforms.Normalize((0.5,), (0.5,))\n]))\n\n# Transformations for the validation & test sets\nval_trans = transforms.Compose(([\n    transforms.ToPILImage(),\n    transforms.Resize((224,224)),\n    transforms.ToTensor(), # divides by 255\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n   # transforms.Normalize((0.1307,), (0.3081,))\n]))","metadata":{"execution":{"iopub.status.busy":"2024-03-04T09:48:18.506889Z","iopub.execute_input":"2024-03-04T09:48:18.507544Z","iopub.status.idle":"2024-03-04T09:48:18.514872Z","shell.execute_reply.started":"2024-03-04T09:48:18.507501Z","shell.execute_reply":"2024-03-04T09:48:18.513927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Asbooka(Dataset):\n    def __init__(self, df, transforms=None):\n        self.df = df\n        self.transforms=transforms\n        self.pics = np.array(df.iloc[:,1:])\n        self.targets = np.array(df.iloc[:,0])\n#         self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n    def __len__(self): return len(self.df)\n    def __getitem__(self, ix):\n        picture = self.pics[ix]\n#         pic=[]\n#         for i in np.arange(3):\n#           pic.append(picture)\n#         print(pic)\n        img = np.array(picture).astype(np.uint8)\n        img = np.repeat(img.reshape(28,28,1), 3, axis=2) # делаем форму (28,28,3) из (28,28,1)\n#         print(img.shape)\n#         print(np.repeat(img.reshape(1,28,28), 3, axis=0).shape)\n        if self.transforms:\n          img=self.transforms(img).to(device)\n#         print(img.shape)\n        target = self.targets[ix]\n        return img, torch.tensor(target).to(device)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-03-04T09:48:22.487499Z","iopub.execute_input":"2024-03-04T09:48:22.487866Z","iopub.status.idle":"2024-03-04T09:48:22.496313Z","shell.execute_reply.started":"2024-03-04T09:48:22.487837Z","shell.execute_reply":"2024-03-04T09:48:22.495185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_data():\n    train = Asbooka(trn_df, train_trans)\n    trn_dl = DataLoader(train, batch_size=254, shuffle=True, drop_last = True)\n    val = Asbooka(val_df, val_trans)\n    val_dl = DataLoader(val, batch_size=64, shuffle=False, drop_last = True)\n    return train, trn_dl, val_dl\ntrain, trn_dl, val_dl = get_data()","metadata":{"execution":{"iopub.status.busy":"2024-03-04T09:51:19.366739Z","iopub.execute_input":"2024-03-04T09:51:19.367102Z","iopub.status.idle":"2024-03-04T09:51:19.470175Z","shell.execute_reply.started":"2024-03-04T09:51:19.367074Z","shell.execute_reply":"2024-03-04T09:51:19.469100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_img(img, title):\n#   plt.figure(figsize=(20,20))\n    npimg=img.cpu().numpy().transpose(1,2,0)\n    plt.title(title)\n    plt.imshow(npimg)#.transpose(1,2,0))\n    plt.show()\n    \nkl = iter(train)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T09:51:29.905563Z","iopub.execute_input":"2024-03-04T09:51:29.906203Z","iopub.status.idle":"2024-03-04T09:51:29.912702Z","shell.execute_reply.started":"2024-03-04T09:51:29.906152Z","shell.execute_reply":"2024-03-04T09:51:29.911721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rr = next(kl)\nprint(rr[0].shape)\nshow_img(rr[0], rr[1])","metadata":{"execution":{"iopub.status.busy":"2024-03-04T09:51:35.424288Z","iopub.execute_input":"2024-03-04T09:51:35.425164Z","iopub.status.idle":"2024-03-04T09:51:35.645203Z","shell.execute_reply.started":"2024-03-04T09:51:35.425119Z","shell.execute_reply":"2024-03-04T09:51:35.644330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **5_Функции_для_train_val_вычисляющие_loss_&_accuracy**","metadata":{}},{"cell_type":"code","source":"def train_batch_loss_acc(x, y, model, opt, loss_fn):\n    model.train()\n    prediction = model(x)\n    \n#     print(prediction.max(1)[1])\n#     print(y)\n    #-------------------------\n    #loss\n    loss = loss_fn(prediction, y)\n#     print(loss)\n#     loss = CrossEntroptLoss(prediction,y)\n#     print( CrossEntroptLoss(prediction,y))\n    #-------------------------\n    #добавление L1-регуляризации\n#     l2_lambda = 0.01\n#     l2_norm = sum(p.abs().sum() for p in model.parameters())\n#     batch_loss = loss + l2_lambda * l2_norm\n    #-------------------------\n    #добавление L2-регуляризации\n    l2_lambda = 0.0001\n    l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n    batch_loss = loss + l2_lambda * l2_norm\n    #-------------------------\n    #accuracy\n    max_values, argmaxes = prediction.max(-1)\n    is_correct = np.mean((argmaxes == y).double().cpu().numpy())\n    #_________________________\n#     print(batch_loss)\n    batch_loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    return batch_loss.item(), is_correct","metadata":{"execution":{"iopub.status.busy":"2024-03-04T09:51:41.232501Z","iopub.execute_input":"2024-03-04T09:51:41.233153Z","iopub.status.idle":"2024-03-04T09:51:41.240741Z","shell.execute_reply.started":"2024-03-04T09:51:41.233122Z","shell.execute_reply":"2024-03-04T09:51:41.239601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def val_batch_loss_acc(x, y, model, opt, loss_fn):\n    model.eval()\n    with torch.no_grad():\n        prediction = model(x)\n    #-------------------------\n    #loss\n    batch_loss = loss_fn(prediction, y)\n#     batch_loss = CrossEntroptLoss(prediction,y)\n    #-------------------------\n    #accuracy\n    max_values, argmaxes = prediction.max(-1)\n    is_correct = np.mean((argmaxes == y).double().cpu().numpy())\n    #_________________________\n    return batch_loss.item(), is_correct","metadata":{"execution":{"iopub.status.busy":"2024-03-04T09:51:45.240442Z","iopub.execute_input":"2024-03-04T09:51:45.240922Z","iopub.status.idle":"2024-03-04T09:51:45.247002Z","shell.execute_reply.started":"2024-03-04T09:51:45.240890Z","shell.execute_reply":"2024-03-04T09:51:45.246125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# здесь по-моему первого достаточно, добавление второго качество почти не улучшает\nfrom torch.optim.lr_scheduler import StepLR\n# scheduler_1 = torch.optim.lr_scheduler.ExponentialLR(optim, gamma=0.9)\nscheduler_2 = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4], gamma=0.1)\n# scheduler_3 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',factor = 0.1, patience = 3)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T10:17:46.145146Z","iopub.execute_input":"2024-03-04T10:17:46.145567Z","iopub.status.idle":"2024-03-04T10:17:46.152544Z","shell.execute_reply.started":"2024-03-04T10:17:46.145537Z","shell.execute_reply":"2024-03-04T10:17:46.151455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **5_Функция потерь CrossEntroptLoss**","metadata":{}},{"cell_type":"code","source":"# def CrossEntroptLoss (y_pred, y_true):\n#     y_pred = y_pred.max(1)[1]\n#     out = (y_pred == y_true).double().numpy()\n#     return 1 - np.mean(out)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **6_Процесс_обучения**","metadata":{}},{"cell_type":"code","source":"# scheduler_2.get_last_lr()[0]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_losses, train_accuracies = [], []\nval_losses, val_accuracies = [], []\nfor epoch in range(12):\n    print(epoch)\n    train_epoch_losses, train_epoch_accuracies = [], []\n    for ix, batch in enumerate(tqdm(trn_dl)):\n        x, y = batch\n        batch_loss_tr, batch_accuracy_tr = train_batch_loss_acc(x, y, model, optimizer, loss_fn)\n        train_epoch_losses.append(batch_loss_tr)\n        train_epoch_accuracies.append(batch_accuracy_tr)\n        if ix%10 == 0:\n            print(f'{ix} batch_train_loss: {np.array(batch_loss_tr)}')\n            print(f'{ix} sum_train_loss: {np.array(train_epoch_losses).mean()}')\n            print(f'{ix} batch_train_acc: {np.array(batch_accuracy_tr)}')\n            print(f'{ix} sum_train_acc: {np.array(train_epoch_accuracies).mean()}', end='\\r')\n    train_losses.append(np.array(train_epoch_losses).mean())\n    train_accuracies.append(np.array(train_epoch_accuracies).mean())\n    \n    val_epoch_losses, val_epoch_accuracies = [], []\n    for ix, batch in enumerate(tqdm(val_dl)):\n        x, y = batch\n        batch_loss_val, batch_accuracy_val = val_batch_loss_acc(x, y, model, optimizer, loss_fn)\n        val_epoch_losses.append(batch_loss_val)\n        val_epoch_accuracies.append(batch_accuracy_val)\n        if ix%10 == 0:\n            print(f'{ix} batch_val_loss: {np.array(batch_loss_val)}')\n            print(f'{ix} sum_val_loss: {np.array(val_epoch_losses).mean()}')\n            print(f'{ix} batch_val_acc: {np.array(batch_accuracy_val)}')\n            print(f'{ix} sum_val_acc: {np.array(val_epoch_accuracies).mean()}', end='\\r')\n    #---------------------------------\n    # изменение шага\n    scheduler_2.step() # меняем_шаг\n    print(scheduler_2.get_last_lr()[0]) # выводим_значение_шага\n    #---------------------------------    \n    val_losses.append(np.array(val_epoch_losses).mean())\n    val_accuracies.append(np.array(val_epoch_accuracies).mean())\n\n    \n    print(f'train_losses: {train_losses}, train_accuracies: {train_accuracies}')\n    print(f'val_losses: {val_losses}, val_accuracies: {val_accuracies}')","metadata":{"execution":{"iopub.status.busy":"2024-03-04T10:17:49.384106Z","iopub.execute_input":"2024-03-04T10:17:49.384463Z","iopub.status.idle":"2024-03-04T10:34:26.422570Z","shell.execute_reply.started":"2024-03-04T10:17:49.384434Z","shell.execute_reply":"2024-03-04T10:34:26.421423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **7_Вывод_результатов**","metadata":{}},{"cell_type":"code","source":"x = np.arange(0,12)\ny1 = train_losses\ny2 = val_losses\nplt.figure(figsize=(12, 7))\nplt.plot(x, y1, 'o-r', alpha=0.7, label=\"train_losses\", lw=5, mec='b', mew=2, ms=10)\nplt.plot(x, y2, 'v-.g', label=\"val_losses\", mec='r', lw=2, mew=2, ms=12)\nplt.legend()\nplt.grid(True)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T10:45:17.282823Z","iopub.execute_input":"2024-03-04T10:45:17.283630Z","iopub.status.idle":"2024-03-04T10:45:17.560170Z","shell.execute_reply.started":"2024-03-04T10:45:17.283598Z","shell.execute_reply":"2024-03-04T10:45:17.559275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = np.arange(0,12)\ny1 = train_accuracies\ny2 = val_accuracies\nplt.figure(figsize=(12, 7))\nplt.plot(x, y1, 'o-r', alpha=0.7, label=\"train_acc\", lw=5, mec='b', mew=2, ms=10)\nplt.plot(x, y2, 'v-.g', label=\"val_acc\", mec='r', lw=2, mew=2, ms=12)\nplt.legend()\nplt.grid(True)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T10:45:22.942843Z","iopub.execute_input":"2024-03-04T10:45:22.943651Z","iopub.status.idle":"2024-03-04T10:45:23.213003Z","shell.execute_reply.started":"2024-03-04T10:45:22.943622Z","shell.execute_reply":"2024-03-04T10:45:23.212009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **8_Предсказание**","metadata":{}},{"cell_type":"code","source":"# random выбор картинок\ndf_test = df.sample(6)\ndf_test","metadata":{"execution":{"iopub.status.busy":"2024-03-04T10:46:09.177937Z","iopub.execute_input":"2024-03-04T10:46:09.178587Z","iopub.status.idle":"2024-03-04T10:46:09.197272Z","shell.execute_reply.started":"2024-03-04T10:46:09.178555Z","shell.execute_reply":"2024-03-04T10:46:09.196290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# преобразования для подачи в модель\nt = Asbooka(df_test, val_trans)\nt_dl = DataLoader(t, batch_size=6, shuffle=True, drop_last = True)\n\n# разделяем картинки и true\nfor i in t_dl:\n    x,y = i\n#     print(x)\n    print(y)\n    \n# блок предсказания класса\n@torch.no_grad()\ndef pred(x, model):\n    model.eval()\n    with torch.no_grad():\n        prediction = model(x)\n    pred_list = prediction.max(1)[1].detach().cpu().numpy()\n    return x.cpu().numpy(), pred_list\n\n# делаем список картинка + предсказание\nimages, predictions = pred(x, model)\ndata = list(zip(images, predictions))\n\nfig, ax = plt.subplots(2, 3, figsize=(10, 7))\naxs = [ax[i, j] for i in range(2) for j in range(3)]\nfor _,i in enumerate(data):\n    axs[_].set_title(i[1], fontweight =\"bold\")\n    axs[_].imshow(i[0].transpose(1, 2, 0))\n#     arrImg = i[0].transpose(1, 2, 0)\n#     plt.title(i[1], fontweight =\"bold\") \n#     plt.imshow(arrImg)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T10:46:11.594182Z","iopub.execute_input":"2024-03-04T10:46:11.594849Z","iopub.status.idle":"2024-03-04T10:46:12.797142Z","shell.execute_reply.started":"2024-03-04T10:46:11.594817Z","shell.execute_reply":"2024-03-04T10:46:12.796155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Шаг 9: Передаем данные**","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-03-04T10:46:23.158126Z","iopub.execute_input":"2024-03-04T10:46:23.158493Z","iopub.status.idle":"2024-03-04T10:46:24.857606Z","shell.execute_reply.started":"2024-03-04T10:46:23.158464Z","shell.execute_reply":"2024-03-04T10:46:24.856741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-04T10:46:27.029488Z","iopub.execute_input":"2024-03-04T10:46:27.029873Z","iopub.status.idle":"2024-03-04T10:46:27.036902Z","shell.execute_reply.started":"2024-03-04T10:46:27.029843Z","shell.execute_reply":"2024-03-04T10:46:27.036021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T10:46:28.757190Z","iopub.execute_input":"2024-03-04T10:46:28.758011Z","iopub.status.idle":"2024-03-04T10:46:28.775011Z","shell.execute_reply.started":"2024-03-04T10:46:28.757981Z","shell.execute_reply":"2024-03-04T10:46:28.774041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Asbookatest(Dataset):\n    def __init__(self, df, transforms=None):\n        self.df = df\n        self.transforms=transforms\n        self.pics = np.array(df)\n#         self.targets = np.array(df.iloc[:,0])\n#         self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n    def __len__(self): return len(self.df)\n    def __getitem__(self, ix):\n        picture = self.pics[ix]\n#         pic=[]\n#         for i in np.arange(3):\n#           pic.append(picture)\n#         print(pic)\n        img = np.array(picture).astype(np.uint8)\n        img = np.repeat(img.reshape(28,28,1), 3, axis=2) # делаем форму (28,28,3) из (28,28,1)\n#         print(img.shape)\n#         print(np.repeat(img.reshape(1,28,28), 3, axis=0).shape)\n        if self.transforms:\n          img=self.transforms(img).to(device)\n#         print(img.shape)\n#         target = self.targets[ix]\n        return img#, torch.tensor(target)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-03-04T10:47:46.805709Z","iopub.execute_input":"2024-03-04T10:47:46.806330Z","iopub.status.idle":"2024-03-04T10:47:46.813562Z","shell.execute_reply.started":"2024-03-04T10:47:46.806302Z","shell.execute_reply":"2024-03-04T10:47:46.812606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_test = Asbookatest(test, val_trans)\ntest_loader = DataLoader(test_test, batch_size=1000, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T10:47:49.348991Z","iopub.execute_input":"2024-03-04T10:47:49.349357Z","iopub.status.idle":"2024-03-04T10:47:49.416947Z","shell.execute_reply.started":"2024-03-04T10:47:49.349327Z","shell.execute_reply":"2024-03-04T10:47:49.415909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\n\nwith torch.no_grad():\n    model.eval()  # Set model to evaluation mode\n    for data in tqdm(test_loader):\n        inputs = data#[0]\n        outputs = model(inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        predictions.extend(predicted.tolist())","metadata":{"execution":{"iopub.status.busy":"2024-03-04T10:47:50.850841Z","iopub.execute_input":"2024-03-04T10:47:50.851191Z","iopub.status.idle":"2024-03-04T10:48:40.529431Z","shell.execute_reply.started":"2024-03-04T10:47:50.851163Z","shell.execute_reply":"2024-03-04T10:48:40.528528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2024-03-04T10:48:46.099906Z","iopub.execute_input":"2024-03-04T10:48:46.100605Z","iopub.status.idle":"2024-03-04T10:48:46.123159Z","shell.execute_reply.started":"2024-03-04T10:48:46.100573Z","shell.execute_reply":"2024-03-04T10:48:46.122206Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/digit-recognizer/sample_submission.csv')\nprint(submission)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T10:48:51.454398Z","iopub.execute_input":"2024-03-04T10:48:51.455066Z","iopub.status.idle":"2024-03-04T10:48:51.478204Z","shell.execute_reply.started":"2024-03-04T10:48:51.455035Z","shell.execute_reply":"2024-03-04T10:48:51.477351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = pd.DataFrame({'ImageId': range(1, len(predictions) + 1), 'Label': predictions})\nsubmission = pd.merge(submission['ImageId'], pred, on='ImageId')\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T10:48:55.195150Z","iopub.execute_input":"2024-03-04T10:48:55.195866Z","iopub.status.idle":"2024-03-04T10:48:55.247810Z","shell.execute_reply.started":"2024-03-04T10:48:55.195834Z","shell.execute_reply":"2024-03-04T10:48:55.246847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred","metadata":{"execution":{"iopub.status.busy":"2024-03-04T10:48:59.722147Z","iopub.execute_input":"2024-03-04T10:48:59.722934Z","iopub.status.idle":"2024-03-04T10:48:59.734716Z","shell.execute_reply.started":"2024-03-04T10:48:59.722891Z","shell.execute_reply":"2024-03-04T10:48:59.733716Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}